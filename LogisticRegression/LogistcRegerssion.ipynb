{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/11 12:57:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"LogistcRegerssion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"titanic.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                                |male  |22.0|1    |0    |A/5 21171       |7.25   |NULL |S       |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                                 |female|26.0|0    |0    |STON/O2. 3101282|7.925  |NULL |S       |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)           |female|35.0|1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                               |male  |35.0|0    |0    |373450          |8.05   |NULL |S       |\n",
      "|6          |0       |3     |Moran, Mr. James                                       |male  |NULL|0    |0    |330877          |8.4583 |NULL |Q       |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                                |male  |54.0|0    |0    |17463           |51.8625|E46  |S       |\n",
      "|8          |0       |3     |Palsson, Master. Gosta Leonard                         |male  |2.0 |3    |1    |349909          |21.075 |NULL |S       |\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |female|27.0|0    |2    |347742          |11.1333|NULL |S       |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                    |female|14.0|1    |0    |237736          |30.0708|NULL |C       |\n",
      "|11         |1       |3     |Sandstrom, Miss. Marguerite Rut                        |female|4.0 |1    |1    |PP 9549         |16.7   |G6   |S       |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                               |female|58.0|0    |0    |113783          |26.55  |C103 |S       |\n",
      "|13         |0       |3     |Saundercock, Mr. William Henry                         |male  |20.0|0    |0    |A/5. 2151       |8.05   |NULL |S       |\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                            |male  |39.0|1    |5    |347082          |31.275 |NULL |S       |\n",
      "|15         |0       |3     |Vestrom, Miss. Hulda Amanda Adolfina                   |female|14.0|0    |0    |350406          |7.8542 |NULL |S       |\n",
      "|16         |1       |2     |Hewlett, Mrs. (Mary D Kingcome)                        |female|55.0|0    |0    |248706          |16.0   |NULL |S       |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                   |male  |2.0 |4    |1    |382652          |29.125 |NULL |Q       |\n",
      "|18         |1       |2     |Williams, Mr. Charles Eugene                           |male  |NULL|0    |0    |244373          |13.0   |NULL |S       |\n",
      "|19         |0       |3     |Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|female|31.0|1    |0    |345763          |18.0   |NULL |S       |\n",
      "|20         |1       |3     |Masselmani, Mrs. Fatima                                |female|NULL|0    |0    |2649            |7.225  |NULL |C       |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = df.select(\n",
    "    \"Survived\",\n",
    "    \"Pclass\",\n",
    "    \"Sex\",\n",
    "    \"Age\",\n",
    "    \"SibSp\",\n",
    "    \"Parch\",\n",
    "    \"Fare\",\n",
    "    \"Embarked\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|  male|NULL|    0|    0| 8.4583|       Q|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|\n",
      "|       1|     2|  male|NULL|    0|    0|   13.0|       S|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|\n",
      "|       1|     3|female|NULL|    0|    0|  7.225|       C|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_final_data = my_cols.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    VectorIndexer,\n",
    "    OneHotEncoder,\n",
    "    StringIndexer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol=\"Sex\", outputCol=\"SexIndex\")\n",
    "gender_encoder = OneHotEncoder(inputCol=\"SexIndex\", outputCol=\"SexVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_indexer = StringIndexer(inputCol=\"Embarked\", outputCol=\"EmbarkIndex\")\n",
    "embark_encoder = OneHotEncoder(inputCol=\"EmbarkIndex\", outputCol=\"EmbarkVec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Pclass\", \"SexVec\", \"EmbarkVec\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"],\n",
    "    outputCol=\"features\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_titanic = LogisticRegression(featuresCol=\"features\", labelCol=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        gender_indexer,\n",
    "        embark_indexer,\n",
    "        gender_encoder,\n",
    "        embark_encoder,\n",
    "        assembler,\n",
    "        log_reg_titanic,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = my_final_data.randomSplit([0.7, 0.3], seed=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+--------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|    Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+--------+--------+\n",
      "|       0|     1|female| 2.0|    1|    2|  151.55|       S|\n",
      "|       0|     1|female|25.0|    1|    2|  151.55|       S|\n",
      "|       0|     1|  male|18.0|    1|    0|   108.9|       C|\n",
      "|       0|     1|  male|19.0|    1|    0|    53.1|       S|\n",
      "|       0|     1|  male|19.0|    3|    2|   263.0|       S|\n",
      "|       0|     1|  male|21.0|    0|    1| 77.2875|       S|\n",
      "|       0|     1|  male|22.0|    0|    0|135.6333|       C|\n",
      "|       0|     1|  male|24.0|    0|    0|    79.2|       C|\n",
      "|       0|     1|  male|24.0|    0|    1|247.5208|       C|\n",
      "|       0|     1|  male|27.0|    0|    2|   211.5|       C|\n",
      "|       0|     1|  male|28.0|    1|    0| 82.1708|       C|\n",
      "|       0|     1|  male|29.0|    0|    0|    30.0|       S|\n",
      "|       0|     1|  male|29.0|    1|    0|    66.6|       S|\n",
      "|       0|     1|  male|30.0|    0|    0|   27.75|       C|\n",
      "|       0|     1|  male|33.0|    0|    0|     5.0|       S|\n",
      "|       0|     1|  male|36.0|    0|    0|  40.125|       C|\n",
      "|       0|     1|  male|36.0|    1|    0|   78.85|       S|\n",
      "|       0|     1|  male|37.0|    0|    1|    29.7|       C|\n",
      "|       0|     1|  male|37.0|    1|    0|    53.1|       S|\n",
      "|       0|     1|  male|38.0|    0|    0|     0.0|       S|\n",
      "+--------+------+------+----+-----+-----+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/11 13:22:55 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/03/11 13:22:55 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    }
   ],
   "source": [
    "fit_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol=\"prediction\", labelCol=\"Survived\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"Survived\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC = my_eval.evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7625603432862507"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
